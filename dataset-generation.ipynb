{"cells":[{"cell_type":"markdown","source":["Code Author:\n","@Naman_Jaswani"],"metadata":{}},{"cell_type":"markdown","source":["# Algo for dataset labeling:\n","\n","#### Lets take an example of   Attribute:  'Brand' , Category: 'Top Wear'\n","\n","1. Loop over all rows unsup_data for top wear\n","2. Get description of i'th row and make it lower case\n","3. Initialize Tags for this i'th row as [O,O,O,O,O,,,,,O] with same length as length of tokenized description text.\n","4. Loop over all sample values for 'Brand'\n","5. If any token in description matches with this value, find and store its index.\n","6. Then still inside the same loop as(1), loop over all stored indices and label them. Consecutive labels will be marked as B_*, I_*."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import numpy as np\n","import pandas as pd\n","\n","from tqdm import tqdm\n","\n","from nltk.tokenize import word_tokenize\n","\n","import os"],"outputs":[],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true}},{"cell_type":"code","execution_count":null,"source":["os.listdir('../input/attributevalue2/')"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["unsup = pd.read_csv('../input/complete-test-data/unsup_data.csv')\n","sample_test = pd.read_csv('../input/sample-data/test.csv')\n","sample_test_output = pd.read_csv('../input/sample-data/test_output.csv')\n","print(unsup.shape)\n","unsup.head()"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["# Top Wear"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["unsup_top = unsup[unsup['Category']=='Top wear'].reset_index(drop='True')\n","unsup_top = unsup_top.dropna().reset_index(drop=True)\n","\n","print(unsup_top.head())\n","print(unsup_top.shape[0])"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["top_wear = pd.read_csv('../input/attributevalue2/Top Wear.csv')\n","top_wear['Sample values split'] = top_wear['Sample values'].apply(lambda x: x.split('||'))\n","dict_top_wear = dict(zip(top_wear['Standardized attributes'], top_wear['Sample values split']))\n","\n","\n","# top_wear\n","bottom_wear = pd.read_csv('../input/attributevalue2/Bottom Wear.csv')\n","bottom_wear['Sample values split'] = bottom_wear['Sample values'].apply(lambda x: x.split('||'))\n","dict_bottom_wear = dict(zip(bottom_wear['Standardized attributes'], bottom_wear['Sample values split']))\n","\n","foot_wear = pd.read_csv('../input/attributevalue2/Foot Wear.csv')\n","foot_wear['Sample values split'] = foot_wear['Sample values'].apply(lambda x: x.split('||'))\n","dict_foot_wear = dict(zip(foot_wear['Standardized attributes'], foot_wear['Sample values split']))\n","# dict_bottom_wear['brand']\n","\n","full_wear = pd.read_csv('../input/attributevalue2/Full Wear.csv')\n","full_wear['Sample values split'] = full_wear['Sample values'].apply(lambda x: x.split('||'))\n","dict_full_wear = dict(zip(full_wear['Standardized attributes'], full_wear['Sample values split']))\n","dict_full_wear['lining_material'] = dict_full_wear['lining material']\n","del dict_full_wear['lining material']\n","\n","accessories = pd.read_csv('../input/attributevalue2/Accessories.csv')\n","accessories['Sample values split'] = accessories['Sample values'].apply(lambda x: x.split('||'))\n","dict_accessories = dict(zip(accessories['Standardized attributes'], accessories['Sample values split']))\n","\n"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["len(dict_bottom_wear['brand'])"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["## Brand"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# Actual code in deployment\n","\n","t = 'B_brand'\n","t_ = 'I_brand'\n","att = 'brand'\n","\n","unsup_top['Tag'] = 0\n","\n","more_brands = ['ONL', 'Humor Gang', 'Celebravo','Zola','Stylum', 'Saibhya','DIVIE', 'hakashi','s v creation', 'FOREVER 21', 'TII','Morten Fashion']\n","recheck_brands = ['and','only', 'basics']\n","\n","for brand in more_brands:\n","    dict_top_wear['brand'].append(brand) # adding another brand\n","\n","for i in tqdm(range(unsup_top.shape[0])):\n","    dcrp = word_tokenize(unsup_top['Descriptions'][i].lower())\n","    unsup_top['Tag'][i] = ['O'] * len(dcrp)\n","    \n","    tag = unsup_top['Tag'][i].copy()\n","    all_indices = []\n","    \n","    dict_top_wear[att] = sorted(dict_top_wear[att], key=len, reverse=True)\n","    for value in dict_top_wear['brand']:\n","        if(value not in recheck_brands):\n","            value = word_tokenize(value.lower())\n","            if any(value==dcrp[ic:ic+len(value)] for ic in range(len(dcrp)-len(value)+1)):\n","                for ic in range(len(dcrp)-len(value)+1):\n","                    indices = []\n","                    if(value==dcrp[ic:ic+len(value)]):\n","                        for j in range(len(value)):\n","                            indices.append(ic+j)\n","                        indices.sort()\n","                        \n","                        for j in indices:\n","                            dcrp[j] = 'naman'\n","                        \n","                        if(len(indices)):\n","                            all_indices.append(indices)\n","\n","            \n","\n","    for indices_ in all_indices: # tagging\n","        flag = True\n","        for k in indices_:\n","            if(tag[k][0] != 'I' and not (tag[k][0]=='B' and k+1<len(tag) and tag[k+1][0]=='I')):\n","                if(flag):\n","                    tag[k] = t\n","                    flag = False\n","                else:\n","                    tag[k] = t_\n","\n","        unsup_top['Tag'][i] = tag\n","        tag = unsup_top['Tag'][i].copy()"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["\n","singles = ['fabric_purity','hem','color_shade','color','detail_placement','ideal_for','collar','fit','occasion','sleeve_style','sleeve_length_type','size','pattern','ornamentation_type',\n","           'suitable_for','topwear_length_type','fabric_purity','fabric_care']\n","\n","for att in tqdm(singles):\n","    # Actual code in deployment\n","\n","    t = f'B_{att}'\n","    t_ = f'I_{att}'\n","    recheck = ['and','only', 'basics']\n","    \n","    if(att == 'brand'):\n","        more_brands = ['ONL', 'Humor Gang', 'Celebravo','Zola','Stylum', 'Saibhya','DIVIE', 'hakashi','s v creation', 'FOREVER 21', 'TII','Morten Fashion']\n","        recheck_brands = ['and','only', 'basics']\n","        \n","        for brand in more_brands:\n","            dict_top_wear[att].append(brand) # adding another brand\n","\n","    for i in range(unsup_top.shape[0]):\n","        dcrp = word_tokenize(unsup_top['Descriptions'][i].lower())\n","        \n","        tag = unsup_top['Tag'][i].copy()\n","        all_indices = []\n","        \n","        dict_top_wear[att] = sorted(dict_top_wear[att], key=len, reverse=True)\n","        for value in dict_top_wear[att]:\n","            if((value not in recheck)):\n","                value = word_tokenize(value.lower())\n","\n","                if any(value==dcrp[ic:ic+len(value)] for ic in range(len(dcrp)-len(value)+1)):\n","                    for ic in range(len(dcrp)-len(value)+1):\n","                        indices = []\n","                        if(value==dcrp[ic:ic+len(value)]):\n","                            for j in range(len(value)):\n","                                indices.append(ic+j)\n","                            indices.sort()\n","\n","                            for j in indices:\n","                                dcrp[j] = 'naman'\n","\n","                            if(len(indices)):\n","                                all_indices.append(indices)\n","\n","\n","        for indices_ in all_indices: # tagging\n","            flag = True\n","            for k in indices_:\n","                if(tag[k][0] != 'I' and not (tag[k][0]=='B' and k+1<len(tag) and tag[k+1][0]=='I')):\n","                    if(flag):\n","                        tag[k] = t\n","                        flag = False\n","                    else:\n","                        tag[k] = t_\n","\n","            unsup_top['Tag'][i] = tag\n","            \n","#     first_att = False"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["unsup_top.to_pickle('TOP WEAR.pickle')"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["# Bottom Wear"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["unsup['Category'].unique()"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["unsup_bottom = unsup[unsup['Category']=='Bottom Wear'].reset_index(drop='True')\n","unsup_bottom = unsup_bottom.dropna().reset_index(drop=True)\n","unsup_bottom.shape"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["unsup_bottom['Tag'] = 0\n","\n","first_att = True\n","\n","singles = ['trouser_occasion','color','jean_bottomwear_length_type','ideal_for','suitable_for','jean_ornamentation_type','trouser_pleats',\n","          'rise','size','jean_wash','pattern','jean_pocket_type','fit','jean_faded','closure','brand','fabric_care', 'fabric']\n","\n","for att in tqdm(singles):\n","    # Actual code in deployment\n","\n","    t = f'B_{att}'\n","    t_ = f'I_{att}'\n","    recheck = ['and','only', 'basics']\n","    \n","    if(att == 'brand'):\n","        more_brands = ['ONL', 'Humor Gang', 'Celebravo','Zola','Stylum', 'Saibhya','DIVIE', 'hakashi','s v creation', 'FOREVER 21', 'TII','Morten Fashion']\n","        recheck_brands = ['and','only', 'basics']\n","        \n","        for brand in more_brands:\n","            dict_bottom_wear[att].append(brand) # adding another brand\n","\n","    for i in range(unsup_bottom.shape[0]):\n","        dcrp = word_tokenize(unsup_bottom['Descriptions'][i].lower())\n","        \n","        if(first_att):\n","            unsup_bottom['Tag'][i] = ['O'] * len(dcrp)\n","        \n","        tag = unsup_bottom['Tag'][i].copy()\n","        all_indices = []\n","        \n","        dict_bottom_wear[att] = sorted(dict_bottom_wear[att], key=len, reverse=True)\n","        for value in dict_bottom_wear[att]:\n","            if((value not in recheck)):\n","                value = word_tokenize(value.lower())\n","\n","                if any(value==dcrp[ic:ic+len(value)] for ic in range(len(dcrp)-len(value)+1)):\n","                    for ic in range(len(dcrp)-len(value)+1):\n","                        indices = []\n","                        if(value==dcrp[ic:ic+len(value)]):\n","                            for j in range(len(value)):\n","                                indices.append(ic+j)\n","                            indices.sort()\n","\n","                            for j in indices:\n","                                dcrp[j] = 'naman'\n","\n","                            if(len(indices)):\n","                                all_indices.append(indices)\n","\n","\n","        for indices_ in all_indices: # tagging\n","            flag = True\n","            for k in indices_:\n","                if(tag[k][0] != 'I' and not (tag[k][0]=='B' and k+1<len(tag) and tag[k+1][0]=='I')):\n","                    if(flag):\n","                        tag[k] = t\n","                        flag = False\n","                    else:\n","                        tag[k] = t_\n","\n","            unsup_bottom['Tag'][i] = tag\n","            \n","    first_att = False"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["unsup_bottom.to_pickle('BOTTOM WEAR.pickle')"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["# Foot Wear"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["unsup['Category'].unique()"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["unsup_foot = unsup[unsup['Category']=='Foot Wear'].reset_index(drop='True')\n","unsup_foot = unsup_foot.dropna().reset_index(drop=True)\n","unsup_foot.shape"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["unsup_foot['Tag'] = 0\n","for i in range(unsup_foot.shape[0]):\n","    dcrp = word_tokenize(unsup_foot['Descriptions'][i].lower())\n","    unsup_foot['Tag'][i] = ['O'] * len(dcrp)\n","            \n","singles = ['shoe_detail_placement','leather_type','occasion','ornamentation_type','footwear_pattern_placement','shoe_tip_shape',\n","           'shoe_color_shade','color','ideal_for','sole_material',\n","          'size','pattern','closure','brand']\n","\n","for att in tqdm(singles):\n","    # Actual code in deployment\n","\n","    t = f'B_{att}'\n","    t_ = f'I_{att}'\n","    recheck = ['and', 'only', 'basics']\n","    \n","    if(att == 'brand'):\n","        more_brands = ['ONL', 'Humor Gang', 'Celebravo','Zola','Stylum', 'Saibhya','DIVIE', 'hakashi','s v creation', 'FOREVER 21', 'TII','Morten Fashion']\n","        recheck_brands = ['and', 'only', 'basics']\n","        \n","        for brand in more_brands:\n","            dict_foot_wear[att].append(brand) # adding another brand\n","\n","    for i in range(unsup_foot.shape[0]):\n","        dcrp = word_tokenize(unsup_foot['Descriptions'][i].lower()).copy()\n","\n","        \n","        tag = unsup_foot['Tag'][i].copy()\n","        all_indices = []\n","        dict_foot_wear[att] = sorted(dict_foot_wear[att], key=len, reverse=True)\n","        \n","        for value in dict_foot_wear[att]:\n","            if((value not in recheck)):\n","                value = word_tokenize(value.lower())\n","\n","                if any(value==dcrp[ic:ic+len(value)] for ic in range(len(dcrp)-len(value)+1)):\n","                    for ic in range(len(dcrp)-len(value)+1):\n","                        indices = []\n","                        if(value==dcrp[ic:ic+len(value)]):\n","                            for j in range(len(value)):\n","                                indices.append(ic+j)\n","                            indices.sort()\n","\n","                            for j in indices:\n","                                dcrp[j] = 'naman'\n","\n","                            if(len(indices)):\n","                                all_indices.append(indices)\n","\n","\n","        for indices_ in all_indices: # tagging\n","            flag = True\n","            for k in indices_:\n","                if(tag[k][0] != 'I' and not (tag[k][0]=='B' and k+1<len(tag) and tag[k+1][0]=='I')):\n","                    if(flag):\n","                        tag[k] = t\n","                        flag = False\n","                    else:\n","                        tag[k] = t_\n","\n","            unsup_foot['Tag'][i] = tag\n","            \n","#     first_att = False"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["## Labeling Ambiguous FOOT WEAR"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["atts = ['inner_material','outer_material','sole_material']\n","\n","for i in range(unsup_foot.shape[0]):\n","    dcrp = word_tokenize(unsup_foot['Descriptions'][i].lower())\n","    tag = unsup_foot['Tag'][i].copy()\n","    \n","    all_lst = []\n","    \n","    attr_name_indices = []\n","    attr_names = []\n","    \n","    v = ['inner']\n","    if any(v==dcrp[i:i+len(v)] for i in range(len(dcrp)-len(v)+1)):\n","        all_lst.append('inner')\n","        att_name = 'inner_material'\n","        attr_name_indices.append(dcrp.index(v[0]))\n","        attr_names.append(att_name)\n","        \n","    v = ['outer']\n","    if any(v==dcrp[i:i+len(v)] for i in range(len(dcrp)-len(v)+1)):\n","        all_lst.append('outer')\n","        att_name = 'outer_material'\n","        attr_name_indices.append(dcrp.index(v[0]))\n","        attr_names.append(att_name)\n","        \n","    v = ['sole']\n","    if any(v==dcrp[i:i+len(v)] for i in range(len(dcrp)-len(v)+1)):\n","        all_lst.append('sole')\n","        att_name = 'sole_material'\n","        attr_name_indices.append(dcrp.index(v[0]))\n","        attr_names.append(att_name)\n","    \n","    all_set = set(all_lst)\n","\n","    if(len(all_set)==0):\n","        continue\n","    \n","    if(len(all_set)==1): # ----------------- Single ambiguous attribute ---------------\n","        attr = list(all_set)[0]\n","        if(attr=='inner'):\n","            t = \"B_inner_material\"\n","            t_ = \"I_inner_material\"\n","        \n","        if(attr=='outer'):\n","            t = \"B_outer_material\"\n","            t_ = \"I_outer_material\"\n","        \n","        if(attr=='sole'):\n","            t = \"B_sole_material\"\n","            t_ = \"I_sole_material\"\n","        \n","        dcrp = word_tokenize(unsup_foot['Descriptions'][i].lower())\n","        \n","        tag = unsup_foot['Tag'][i].copy()\n","        all_indices = []\n","        dict_foot_wear[att] = sorted(dict_foot_wear[att], key=len, reverse=True)\n","        \n","        for value in dict_foot_wear[att_name]:\n","            value = word_tokenize(value.lower())\n","            if any(value==dcrp[ic:ic+len(value)] for ic in range(len(dcrp)-len(value)+1)):\n","                for ic in range(len(dcrp)-len(value)+1):\n","                    indices = []\n","                    if(value==dcrp[ic:ic+len(value)]):\n","                        for j in range(len(value)):\n","                            indices.append(ic+j)\n","                        indices.sort()\n","\n","                        for j in indices:\n","                            dcrp[j] = 'naman'\n","\n","                        if(len(indices)):\n","                            all_indices.append(indices)\n","        \n","        for indices_ in all_indices: # tagging\n","            flag = True\n","            for k in indices_:\n","                if(tag[k][0] != 'I' and not (tag[k][0]=='B' and k+1<len(tag) and tag[k+1][0]=='I')):\n","                    if(flag):\n","                        tag[k] = t\n","                        flag = False\n","                    else:\n","                        tag[k] = t_\n","\n","            unsup_foot['Tag'][i] = tag\n","            \n","    if(len(all_set) > 1): #---------------- Multiple ambiguous attribute occurances ---------------\n","        \n","        for ix in range(len(attr_name_indices)):\n","            att_index = attr_name_indices[ix]\n","            att_name = attr_names[ix]\n","            if(att_name=='inner_material'):\n","                t = \"B_inner_material\"\n","                t_ = \"I_inner_material\"\n","        \n","            if(att_name=='outer_material'):\n","                t = \"B_outer_material\"\n","                t_ = \"I_outer_material\"\n","\n","            if(att_name=='sole_material'):\n","                t = \"B_sole_material\"\n","                t_ = \"I_sole_material\"\n","            \n","            done = False\n","            \n","            for x in [1, 2, 3]:\n","            # Bi-gram analysis\n","                all_indices = []\n","                dict_foot_wear[att] = sorted(dict_foot_wear[att], key=len, reverse=True)\n","                \n","                for value in dict_foot_wear[att_name]:\n","                    value = word_tokenize(value.lower())\n","                    indices = []\n","                    if (value==dcrp[att_index+x:att_index+x+len(value)] or\n","                            value==dcrp[att_index-x-len(value)+1:att_index-x+1]):\n","                        \n","                        done = True\n","                        for j in range(len(value)):\n","                            if(value==dcrp[att_index+x:att_index+x+len(value)]):\n","                                found_idx = att_index+x\n","                            else:\n","                                found_idx = att_index-x-len(value)+1\n","                            if(np.abs(found_idx - att_index) <= 3):\n","                                indices.append(found_idx)\n","                                indices.sort()\n","\n","                    for j in indices:\n","                        dcrp[j] = 'naman'\n","\n","                    if(len(indices)):\n","                        all_indices.append(indices)\n","                \n","#                 print(t)\n","                for indices_ in all_indices: # tagging\n","                    flag = True\n","                    for k in indices_:\n","                        if(tag[k][0] != 'I' and not (tag[k][0]=='B' and k+1<len(tag) and tag[k+1][0]=='I')):\n","                            if(flag):\n","                                tag[k] = t\n","                                flag = False\n","                            else:\n","                                tag[k] = t_\n","\n","                    unsup_foot['Tag'][i] = tag\n","                    tag = unsup_foot['Tag'][i].copy()\n","\n","                if(done):\n","                    break"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["unsup_foot.to_pickle('FOOT WEAR.pickle')"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["# Full Wear"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["unsup['Category'].unique()"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["unsup_full = unsup[unsup['Category']=='Full wear'].reset_index(drop='True')\n","unsup_full = unsup_full.dropna().reset_index(drop=True)\n","unsup_full"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["unsup_full['Tag'] = 0\n","for i in range(unsup_full.shape[0]):\n","    dcrp = word_tokenize(unsup_full['Descriptions'][i].lower())\n","    unsup_full['Tag'][i] = ['O'] * len(dcrp)\n","\n","singles = ['sari_blouse_stitch_type','gown_weave_type','gown_belt_material','sari_border_details','sari_border_length','brand','gown_bust_size','gown_closure','color','gown_design','detail_placement','sari_embroidery_method','sari_type_of_embroidery','ideal_for','dress_topwear_length_type',\n","          'occasion','ornamentation_type','pattern','sari_fabric_purity','dress_shape','size','sleeve_length_type','sleeve_style','collar','fabric_care','sari_decorative_material','fabric']\n","\n","for att in tqdm(singles):\n","    # Actual code in deployment\n","\n","    t = f'B_{att}'\n","    t_ = f'I_{att}'\n","    recheck = ['and','only', 'basics']\n","    \n","    if(att == 'brand'):\n","        more_brands = ['ONL', 'Humor Gang', 'Celebravo','Zola','Stylum', 'Saibhya','DIVIE', 'hakashi','s v creation', 'FOREVER 21', 'TII','Morten Fashion']\n","        recheck_brands = ['and','only', 'basics']\n","        \n","        for brand in more_brands:\n","            dict_full_wear[att].append(brand) # adding another brand\n","\n","    for i in range(unsup_full.shape[0]):\n","        dcrp = word_tokenize(unsup_full['Descriptions'][i].lower())\n","        \n","        tag = unsup_full['Tag'][i].copy()\n","        all_indices = []\n","        dict_full_wear[att] = sorted(dict_full_wear[att], key=len, reverse=True)\n","        \n","        for value in dict_full_wear[att]:\n","            if((value not in recheck)):\n","                value = word_tokenize(value.lower())\n","\n","                if any(value==dcrp[ic:ic+len(value)] for ic in range(len(dcrp)-len(value)+1)):\n","                    for ic in range(len(dcrp)-len(value)+1):\n","                        indices = []\n","                        if(value==dcrp[ic:ic+len(value)]):\n","                            for j in range(len(value)):\n","                                indices.append(ic+j)\n","                            indices.sort()\n","\n","                            for j in indices:\n","                                dcrp[j] = 'naman'\n","\n","                            if(len(indices)):\n","                                all_indices.append(indices)\n","\n","        for indices_ in all_indices: # tagging\n","            flag = True\n","            for k in indices_:\n","                if(tag[k][0] != 'I' and not (tag[k][0]=='B' and k+1<len(tag) and tag[k+1][0]=='I')):\n","                    if(flag):\n","                        tag[k] = t\n","                        flag = False\n","                    else:\n","                        tag[k] = t_\n","\n","            unsup_full['Tag'][i] = tag\n","            tag = unsup_full['Tag'][i].copy()\n","            "],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["## Labeling Ambiguous Full Wear"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["atts = ['sari_blouse_fabric','lining_material']\n","\n","for i in range(unsup_full.shape[0]):\n","    dcrp = word_tokenize(unsup_full['Descriptions'][i].lower())\n","    tag = unsup_full['Tag'][i].copy()\n","    \n","    all_lst = []\n","    \n","    attr_name_indices = []\n","    attr_names = []\n","    \n","    v = ['blouse']\n","    if any(v==dcrp[i:i+len(v)] for i in range(len(dcrp)-len(v)+1)):\n","        all_lst.append('blouse')\n","        att_name = 'sari_blouse_fabric'\n","        attr_name_indices.append(dcrp.index(v[0]))\n","        attr_names.append(att_name)\n","\n","        \n","    v = ['lining']\n","    if any(v==dcrp[i:i+len(v)] for i in range(len(dcrp)-len(v)+1)):\n","        all_lst.append('lining')\n","        att_name = 'lining_material'\n","        attr_name_indices.append(dcrp.index(v[0]))\n","        attr_names.append(att_name)\n","    \n","    all_set = set(all_lst)\n","\n","    if(len(all_set)==0):\n","        continue\n","    \n","    if(len(all_set)==1): # ----------------- Single ambiguous attribute ---------------\n","        attr = list(all_set)[0]\n","        if(attr=='blouse'):\n","            t = \"B_sari_blouse_fabric\"\n","            t_ = \"I_sari_blouse_fabric\"\n","\n","        \n","        if(attr=='lining'):\n","            t = \"B_lining_material\"\n","            t_ = \"I_lining_material\"\n","        \n","        dcrp = word_tokenize(unsup_full['Descriptions'][i].lower())\n","        \n","        tag = unsup_full['Tag'][i].copy()\n","        all_indices = []\n","        dict_full_wear[att] = sorted(dict_full_wear[att], key=len, reverse=True)\n","        \n","        for value in dict_full_wear[att_name]:\n","            value = word_tokenize(value.lower())\n","\n","            if any(value==dcrp[ic:ic+len(value)] for ic in range(len(dcrp)-len(value)+1)):\n","                for ic in range(len(dcrp)-len(value)+1):\n","                    indices = []\n","                    if(value==dcrp[ic:ic+len(value)]):\n","                        for j in range(len(value)):\n","                            indices.append(ic+j)\n","                        indices.sort()\n","\n","                        for j in indices:\n","                            dcrp[j] = 'naman'\n","\n","                        if(len(indices)):\n","                            all_indices.append(indices)\n","        \n","        for indices_ in all_indices: # tagging\n","            flag = True\n","            for k in indices_:\n","                if(tag[k][0] != 'I' and not (tag[k][0]=='B' and k+1<len(tag) and tag[k+1][0]=='I')):\n","                    if(flag):\n","                        tag[k] = t\n","                        flag = False\n","                    else:\n","                        tag[k] = t_\n","\n","            unsup_full['Tag'][i] = tag\n","            tag = unsup_full['Tag'][i].copy()\n","        \n","    else: #---------------- Multiple ambiguous attribute occurances ---------------\n","        for ix in range(len(attr_name_indices)):\n","            att_index = attr_name_indices[ix]\n","            att_name = attr_names[ix]\n","#             print(att_name)\n","            \n","            if(attr=='blouse'):\n","                t = \"B_sari_blouse_fabric\"\n","                t_ = \"I_sari_blouse_fabric\"\n","\n","\n","            if(attr=='lining'):\n","                t = \"B_lining_material\"\n","                t_ = \"I_lining_material\"\n","            \n","            done = False\n","            for x in [1, 2]:\n","            # Bi-gram analysis\n","                all_indices = []\n","                dict_full_wear[att] = sorted(dict_full_wear[att], key=len, reverse=True)\n","                for value in dict_full_wear[att_name]:\n","                    value = word_tokenize(value.lower())\n","                    indices = []\n","                    if (value==dcrp[att_index+x:att_index+x+len(value)] or\n","                            value==dcrp[att_index-x-len(value)+1:att_index-x+1]):\n","                        \n","                        done = True\n","                        for j in range(len(value)):\n","                            if(value==dcrp[att_index+x:att_index+x+len(value)]):\n","                                found_idx = att_index+x\n","                            else:\n","                                found_idx = att_index-x-len(value)+1\n","                                \n","#                             print(att_index, found_idx)\n","                            if(np.abs(found_idx - att_index) <= 3):\n","                                indices.append(found_idx)\n","                                indices.sort()\n","\n","                    for j in indices:\n","                        dcrp[j] = 'naman'\n","\n","                    if(len(indices)):\n","                        all_indices.append(indices)\n","                \n","                all_indices.sort()\n","                for indices_ in all_indices: # tagging\n","                    flag = True\n","                    for k in indices_:\n","                        if(tag[k][0] != 'I' and not (tag[k][0]=='B' and k+1<len(tag) and tag[k+1][0]=='I')):\n","                            if(flag):\n","                                tag[k] = t\n","                                flag = False\n","                            else:\n","                                tag[k] = t_\n","\n","                    unsup_full['Tag'][i] = tag\n","                    tag = unsup_full['Tag'][i].copy()\n","\n","                if(done):\n","                    break"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["unsup_full.to_pickle('FULL WEAR.pickle')"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["# Accessories"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["unsup['Category'].unique()"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["unsup_acc = unsup[unsup['Category']=='Accessories'].reset_index(drop='True')\n","unsup_acc = unsup_acc.dropna().reset_index(drop=True)\n","unsup_acc"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["unsup_acc['vertical'].unique()"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["## EDA for accessories"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["\n","for i in range(unsup_acc.shape[0]):\n","    dcrp = word_tokenize(unsup_acc['Descriptions'][i].lower())\n","    \n","    all_lst = []\n","    \n","    attr_name_indices = []\n","    attr_names = []\n","    \n","    v = ['watch']\n","    if any(v==dcrp[i:i+len(v)] for i in range(len(dcrp)-len(v)+1)):\n","        all_lst.append('watch')\n","        att_name = 'watch'\n","        attr_name_indices.append(dcrp.index(v[0]))\n","        attr_names.append(att_name)\n","        \n","    v = ['suitcase']\n","    if any(v==dcrp[i:i+len(v)] for i in range(len(dcrp)-len(v)+1)):\n","        all_lst.append('suitcase')\n","        att_name = 'suitcase'\n","        attr_name_indices.append(dcrp.index(v[0]))\n","        attr_names.append(att_name)\n","        \n","    v = ['jewellery']\n","    if any(v==dcrp[i:i+len(v)] for i in range(len(dcrp)-len(v)+1)):\n","        all_lst.append('jewellery')\n","        att_name = 'jewellery'\n","        attr_name_indices.append(dcrp.index(v[0]))\n","        attr_names.append(att_name)\n","        \n","    v = ['bag']\n","    if any(v==dcrp[i:i+len(v)] for i in range(len(dcrp)-len(v)+1)):\n","        all_lst.append('bag')\n","        att_name = 'bag'\n","        attr_name_indices.append(dcrp.index(v[0]))\n","        attr_names.append(att_name)\n","    \n","    v = ['sunglasses']\n","    if any(v==dcrp[i:i+len(v)] for i in range(len(dcrp)-len(v)+1)):\n","        all_lst.append('sunglasses')\n","        att_name = 'sunglasses'\n","        attr_name_indices.append(dcrp.index(v[0]))\n","        attr_names.append(att_name)\n","    \n","    all_set = set(all_lst)\n","    \n","    "],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["## Labeling General Accessories [att]"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["unsup_acc['Tag'] = 0\n","for i in range(unsup_acc.shape[0]):\n","    dcrp = word_tokenize(unsup_acc['Descriptions'][i].lower())\n","    unsup_acc['Tag'][i] = ['O'] * len(dcrp)\n","\n","singles = ['size','color','occasion','material','ideal_for','shape','closure','brand']\n","\n","for att in tqdm(singles):\n","    # Actual code in deployment\n","\n","    t = f'B_{att}'\n","    t_ = f'I_{att}'\n","    recheck = ['and','only', 'basics']\n","    \n","    if(att == 'brand'):\n","        more_brands = ['ONL', 'Humor Gang', 'Celebravo','Zola','Stylum', 'Saibhya','DIVIE', 'hakashi','s v creation', 'FOREVER 21', 'TII','Morten Fashion']\n","        recheck_brands = ['and','only', 'basics']\n","        \n","        for brand in more_brands:\n","            dict_accessories[att].append(brand) # adding another brand\n","\n","    for i in range(unsup_acc.shape[0]):\n","        dcrp = word_tokenize(unsup_acc['Descriptions'][i].lower())\n","        \n","        tag = unsup_acc['Tag'][i].copy()\n","        all_indices = []\n","        \n","        dict_accessories[att] = sorted(dict_accessories[att], key=len, reverse=True)\n","        for value in dict_accessories[att]:\n","            if((value not in recheck)):\n","                value = word_tokenize(value.lower())\n","\n","                if any(value==dcrp[ic:ic+len(value)] for ic in range(len(dcrp)-len(value)+1)):\n","                    for ic in range(len(dcrp)-len(value)+1):\n","                        indices = []\n","                        if(value==dcrp[ic:ic+len(value)]):\n","                            for j in range(len(value)):\n","                                indices.append(ic+j)\n","                            indices.sort()\n","\n","                            for j in indices:\n","                                dcrp[j] = 'naman'\n","\n","                            if(len(indices)):\n","                                all_indices.append(indices)\n","\n","        for indices_ in all_indices: # tagging\n","            flag = True\n","            for k in indices_:\n","                if(tag[k][0] != 'I' and not (tag[k][0]=='B' and k+1<len(tag) and tag[k+1][0]=='I')):\n","                    if(flag):\n","                        tag[k] = t\n","                        flag = False\n","                    else:\n","                        tag[k] = t_\n","\n","            unsup_acc['Tag'][i] = tag\n","            tag = unsup_acc['Tag'][i].copy()\n","            "],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["def general(singles, dcrp, test_tag):\n","    \n","    for att in (singles):\n","        t = f'B_{att}'\n","        t_ = f'I_{att}'\n","        recheck = ['and','only', 'basics']\n","\n","        if(att == 'brand'):\n","            more_brands = ['ONL', 'Humor Gang', 'Celebravo','Zola','Stylum', 'Saibhya','DIVIE', 'hakashi','s v creation', 'FOREVER 21', 'TII','Morten Fashion']\n","            recheck_brands = ['and','only', 'basics', 'high quality']\n","\n","            for brand in more_brands:\n","                dict_accessories[att].append(brand) # adding another brand\n","\n","        tag = test_tag.copy()\n","        all_indices = []\n","\n","        dict_accessories[att] = sorted(dict_accessories[att], key=len, reverse=True)\n","        for value in dict_accessories[att]:\n","            if((value not in recheck)):\n","                value = word_tokenize(value.lower())\n","\n","                if any(value==dcrp[ic:ic+len(value)] for ic in range(len(dcrp)-len(value)+1)):\n","                    for ic in range(len(dcrp)-len(value)+1):\n","                        indices = []\n","                        if(value==dcrp[ic:ic+len(value)]):\n","                            for j in range(len(value)):\n","                                indices.append(ic+j)\n","                            indices.sort()\n","\n","                            for j in indices:\n","                                dcrp[j] = 'naman'\n","\n","                            if(len(indices)):\n","                                all_indices.append(indices)\n","\n","        for indices_ in all_indices: # tagging\n","            flag = True\n","            for k in indices_:\n","                if(tag[k][0] != 'I' and not (tag[k][0]=='B' and k+1<len(tag) and tag[k+1][0]=='I')):\n","                    if(flag):\n","                        tag[k] = t\n","                        flag = False\n","                    else:\n","                        tag[k] = t_\n","\n","            test_tag = tag\n","            tag = test_tag.copy()\n","        \n","    return tag"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["def ambiguous_case(singles, dcrp, test_tag, v_s):\n","\n","    tag = test_tag.copy()\n","    \n","    all_lst = []\n","    \n","    attr_name_indices = []\n","    attr_names = []\n","    \n","    for v in v_s:\n","        idx = v_s.index(v)\n","        attr = singles[idx]\n","        \n","        if(len(v)>1):\n","            for vv in v:\n","                if any(vv==dcrp[i:i+len(vv)] for i in range(len(dcrp)-len(vv)+1)):\n","                    all_lst.append(vv[0])\n","                    att_name = attr\n","                    attr_name_indices.append(dcrp.index(vv[0]))\n","                    attr_names.append(att_name)\n","        else:\n","            if any(v==dcrp[i:i+len(v)] for i in range(len(dcrp)-len(v)+1)):\n","                all_lst.append(v[0])\n","                att_name = attr\n","                attr_name_indices.append(dcrp.index(v[0]))\n","                attr_names.append(att_name)\n","        \n","    \n","    all_set = set(all_lst)\n","\n","    if(len(all_set)==0):\n","        return tag\n","    \n","    if(len(all_set)==1): # ----------------- Single ambiguous attribute ---------------\n","        t = f'B_{att_name}'\n","        t_ = f'I_{att_name}'        \n","        \n","        tag = test_tag.copy()\n","        all_indices = []\n","        dict_accessories[att] = sorted(dict_accessories[att], key=len, reverse=True)\n","        \n","        for value in dict_accessories[att_name]:\n","            value = word_tokenize(value.lower())\n","\n","            if any(value==dcrp[ic:ic+len(value)] for ic in range(len(dcrp)-len(value)+1)):\n","                for ic in range(len(dcrp)-len(value)+1):\n","                    indices = []\n","                    if(value==dcrp[ic:ic+len(value)]):\n","                        for j in range(len(value)):\n","                            indices.append(ic+j)\n","                        indices.sort()\n","\n","                        for j in indices:\n","                            dcrp[j] = 'naman'\n","\n","                        if(len(indices)):\n","                            all_indices.append(indices)\n","        \n","        for indices_ in all_indices: # tagging\n","            flag = True\n","            for k in indices_:\n","                if(tag[k][0] != 'I' and not (tag[k][0]=='B' and k+1<len(tag) and tag[k+1][0]=='I')):\n","                    if(flag):\n","                        tag[k] = t\n","                        flag = False\n","                    else:\n","                        tag[k] = t_\n","\n","            test_tag = tag\n","            tag = test_tag.copy()\n","        \n","            \n","    else: #---------------- Multiple ambiguous attribute occurances ---------------\n","        for ix in range(len(attr_name_indices)):\n","            att_index = attr_name_indices[ix]\n","            att_name = attr_names[ix]\n","            \n","            t = f'B_{att_name}'\n","            t_ = f'I_{att_name}'\n","            \n","            done = False\n","            for x in [1, 2, 3]:\n","            # Bi-gram analysis\n","                all_indices = []\n","                dict_accessories[att] = sorted(dict_accessories[att], key=len, reverse=True)\n","                \n","                for value in dict_accessories[att_name]:\n","                    value = word_tokenize(value.lower())\n","                    indices = []\n","                    if (value==dcrp[att_index+x:att_index+x+len(value)] or\n","                            value==dcrp[att_index-x-len(value)+1:att_index-x+1]):\n","                        \n","                        done = True\n","                        for j in range(len(value)):\n","                            if(value==dcrp[att_index+x:att_index+x+len(value)]):\n","                                found_idx = att_index+x\n","                            else:\n","                                found_idx = att_index-x-len(value)+1\n","                                \n","                            if(np.abs(found_idx - att_index) <= 3):\n","                                indices.append(found_idx)\n","                                indices.sort()\n","\n","                    for j in indices:\n","                        dcrp[j] = 'naman'\n","\n","                    if(len(indices)):\n","                        all_indices.append(indices)\n","                \n","                all_indices.sort()\n","                for indices_ in all_indices: # tagging\n","                    flag = True\n","                    for k in indices_:\n","                        if(tag[k][0] != 'I' and not (tag[k][0]=='B' and k+1<len(tag) and tag[k+1][0]=='I')):\n","                            if(flag):\n","                                tag[k] = t\n","                                flag = False\n","                            else:\n","                                tag[k] = t_\n","\n","                    test_tag = tag\n","                    tag = test_tag.copy()\n","\n","                if(done):\n","                    break\n","\n","    return tag"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["\n","for i in tqdm(range(unsup_acc.shape[0])):\n","    dcrp = word_tokenize(unsup_acc['Descriptions'][i].lower())\n","    tag = unsup_acc['Tag'][i].copy()\n","    \n","    if('sunglasses' in dcrp or 'sunglasses' in dcrp or 'glasses' in dcrp):\n","        # General labels\n","        singles = ['sunglass_purpose','sunglass_face_type','sunglass_frame','sunglass_design']\n","        unsup_acc['Tag'][i] = general(singles, dcrp, tag)\n","        \n","        #material\n","        abmiguous = ['sunglass_frame_material','sunglass_lens_material']\n","        tag = unsup_acc['Tag'][i].copy()\n","        dcrp = word_tokenize(unsup_acc['Descriptions'][i].lower())\n","        v_s = [[['frame'],['frames']], [['lens'],['lenses']]]\n","        unsup_acc['Tag'][i] = ambiguous_case(abmiguous, dcrp, tag, v_s)\n","        \n","        #color\n","        abmiguous = ['frame_color','sunglass_lens_color']\n","        tag = unsup_acc['Tag'][i].copy()\n","        dcrp = word_tokenize(unsup_acc['Descriptions'][i].lower())\n","        v_s = [[['frame'],['frames']], [['lens'],['lenses']]]\n","        unsup_acc['Tag'][i] = ambiguous_case(abmiguous, dcrp, tag, v_s)\n","        \n","    \n","    if('suitcase' in dcrp or 'bag' in dcrp):\n","        # General labels\n","        singles = ['strap_material','suitcase_detail_placement','bag_leather_type','suitcase_ornamentation_type','pattern','strap_color']\n","        unsup_acc['Tag'][i] = general(singles, dcrp, tag)\n","        \n","    if('watch' in dcrp or 'clock' in dcrp):\n","        # General labels\n","        singles = ['watch_dial_shape','watch_strap_design']\n","        unsup_acc['Tag'][i] = general(singles, dcrp, tag)\n","        \n","        #material\n","        abmiguous = ['watch_case_bezel_material','strap_material']\n","        tag = unsup_acc['Tag'][i].copy()\n","        dcrp = word_tokenize(unsup_acc['Descriptions'][i].lower())\n","        v_s = [[['case'],['bezel']], ['strap']]\n","        unsup_acc['Tag'][i] = ambiguous_case(abmiguous, dcrp, tag, v_s)\n","        \n","        #color\n","        abmiguous = ['dial_color','strap_color']\n","        tag = unsup_acc['Tag'][i].copy()\n","        dcrp = word_tokenize(unsup_acc['Descriptions'][i].lower())\n","        v_s = [['dial'], ['strap']]\n","        unsup_acc['Tag'][i] = ambiguous_case(abmiguous, dcrp, tag, v_s)\n","        \n","    if('jewellery' in dcrp or 'jewel' in dcrp):\n","        # General labels\n","        singles = ['jewellery_set_finish','jewellery_set_earring_length']\n","        unsup_acc['Tag'][i] = general(singles, dcrp, tag)\n","        \n","        #material\n","        abmiguous = ['jewellery_set_base_material','jewellery_set_artificial_pearl_material','jewellery_set_diamond_shape','jewellery_set_gemstone']\n","        tag = unsup_acc['Tag'][i].copy()\n","        dcrp = word_tokenize(unsup_acc['Descriptions'][i].lower())\n","        v_s = [[['case'],['bezel'],['body']], ['artificial pearl'],['diamond'], ['gemstone']]\n","        unsup_acc['Tag'][i] = ambiguous_case(abmiguous, dcrp, tag, v_s)\n","        \n","        #color\n","        abmiguous = ['jewellery_set_metal_color','jewellery_set_emerald_color','jewellery_set_pearl_color','jewellery_set_ruby_color','jewellery_set_sapphire_color','jewellery_set_silver_color']\n","        tag = unsup_acc['Tag'][i].copy()\n","        dcrp = word_tokenize(unsup_acc['Descriptions'][i].lower())\n","        v_s = [['metal'], ['emerald'], ['pearl'],['ruby'],['sapphire'],['silver']]\n","        unsup_acc['Tag'][i] = ambiguous_case(abmiguous, dcrp, tag, v_s)\n","        "],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["unsup_acc.to_pickle('ACCESSORIES.pickle')"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{"trusted":true}}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}